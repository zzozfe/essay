{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT sentiment analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKRJoQg_gYWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install rarfile\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPQxQtrssEVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrhjGu0xZJ6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "   \n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = '1Vd1eT_YVwdijl1GZqQdP1Ep0OGS28tay'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('longdata.rar')\n",
        "file_id = '13vKE-OHTfeYzZVGxUOjjPQ_lzPljTeH0'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('sumdata.rar')\n",
        "file_id = '16zame2wNb25A4BP67VxON5ft-mJ3N_2n'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('trains.csv')\n",
        "file_id = '1Gd20wkDA_vpxdbHGV45RoVQZkmyynamu'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('train_neu.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnZo8LCBjGrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_id = '15z3JquZZXwWF0X4Vue3sh6Rvbup1lz9k'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('trains.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N29IS_c9e4SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import rarfile\n",
        "\n",
        "rf = rarfile.RarFile('longdata.rar')        \n",
        "rf.extractall()               \n",
        "rf.close()\n",
        "rf = rarfile.RarFile('sumdata.rar')        \n",
        "rf.extractall()               \n",
        "rf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPdobSZagruN",
        "colab_type": "code",
        "outputId": "010ee02e-9ec8-43ae-839d-ed097bbe6eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from operator import itemgetter\n",
        "import re\n",
        "\n",
        "path1 = os.listdir('./longdata')\n",
        "path2 = os.listdir('./sumdata')\n",
        "path2.remove( '.ipynb_checkpoints')\n",
        "path1.sort()\n",
        "path2 = sorted(path2, key = lambda x : int(x.replace('_','').split('.')[0]))\n",
        "\n",
        "\n",
        "def readdata(data, stopword, long):\n",
        "    tt = ''\n",
        "    if long == 'long':\n",
        "        with open('./longdata/' + data,'r', encoding='big5') as t921:\n",
        "            for l in t921:\n",
        "                if l != '' :\n",
        "                    tt += l\n",
        "    elif long == 'short':    \n",
        "        with open('./sumdata/' + data,'r') as t921:\n",
        "            for l in t921:\n",
        "                if l != '' :\n",
        "                    tt += l            \n",
        "    for c in stopword2:\n",
        "        tt = tt.replace(c,'')\n",
        "    tt = tt.replace('消費者物價指數','CPI')\n",
        "    tt = tt.replace('CPICPI','CPI')\n",
        "    tt = tt.replace('製造業採購經理人指數','PMI')\n",
        "    tt = tt.replace('製造業經理人指數','NMI')\n",
        "    #tt = tt.split('，')\n",
        "    tt = re.split(r'[；。]', tt)\n",
        "    return tt            \n",
        "\n",
        "stopword = ['\\n','\\r','\\t','\\u3000','：','；',' ','、','）','(','（',')','.','亦','在','將','至',\n",
        "            '的','但','卻','及','為','且','呈','以','則','與','若','仍','惟','之','」','「','<','-',\n",
        "           'http//wwwcbcgovtw>98']\n",
        "stopword2 = ['\\n','\\r','\\t','\\u3000']           \n",
        "documents1 = []\n",
        "documents2 = []\n",
        "\n",
        "for i in path1:\n",
        "    documents1 += readdata(i, stopword2, long = 'long')\n",
        "for i in path2:\n",
        "    documents2 += readdata(i, stopword2, long = 'short')\n",
        "    \n",
        "print(f'會議記錄 : {len(documents1)}句')\n",
        "print(f'新聞稿 : {len(documents2)}句')    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "會議記錄 : 1260句\n",
            "新聞稿 : 2990句\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFcv61UfmuFL",
        "colab_type": "code",
        "outputId": "32019960-3694-4eba-cb63-bf02f335975f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "trains = pd.read_csv('trains.csv', encoding = 'utf-8')\n",
        "print(trains.shape)\n",
        "trains.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4250, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentent</th>\n",
              "      <th>non_sentent</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['討論', '事項', '：', '國內外', '經濟', '金融', '情勢', '與'...</td>\n",
              "      <td>討論事項：國內外經濟金融情勢與本行貨幣政策提請討論</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['壹', '、', '國內外', '經濟', '金融', '情勢', '1', '經濟',...</td>\n",
              "      <td>壹、國內外經濟金融情勢1經濟研究處說明：一、 國際經濟金融情勢隨全球製造業及貿易活動漸趨活絡...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['多數', '經濟體', '展望', '趨於', '樂觀']</td>\n",
              "      <td>多數經濟體展望趨於樂觀</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['其中', '美國', '、', '日本', '、', '歐元區', '等', '經濟',...</td>\n",
              "      <td>其中美國、日本、歐元區等經濟皆穩健成長亞洲經濟體成長率多高於上年惟中國大陸成長則略緩</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['先進', '經濟體', '因', '經濟', '復甦', '預期', '本年', '通膨...</td>\n",
              "      <td>先進經濟體因經濟復甦預期本年通膨溫和成長</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             sentent  ...    labels\n",
              "0  ['討論', '事項', '：', '國內外', '經濟', '金融', '情勢', '與'...  ...   neutral\n",
              "1  ['壹', '、', '國內外', '經濟', '金融', '情勢', '1', '經濟',...  ...  positive\n",
              "2                    ['多數', '經濟體', '展望', '趨於', '樂觀']  ...  positive\n",
              "3  ['其中', '美國', '、', '日本', '、', '歐元區', '等', '經濟',...  ...   neutral\n",
              "4  ['先進', '經濟體', '因', '經濟', '復甦', '預期', '本年', '通膨...  ...   neutral\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoNALf45j2A2",
        "colab_type": "code",
        "outputId": "427aba38-7753-4d9e-8af7-df41fc54c8a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "trains['labels'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     2373\n",
              "negative    1023\n",
              "positive     531\n",
              "unk          323\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceZvvS7x4T79",
        "colab_type": "code",
        "outputId": "bb74f1a2-1494-462a-c550-567f13d5dd1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "label_dict = {'positive':0, 'negative':1, 'neutral':2, 'unk':2}\n",
        "trains['labels'] = trains['labels'].map(label_dict)\n",
        "trains.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentent</th>\n",
              "      <th>non_sentent</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['討論', '事項', '：', '國內外', '經濟', '金融', '情勢', '與'...</td>\n",
              "      <td>討論事項：國內外經濟金融情勢與本行貨幣政策提請討論</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['壹', '、', '國內外', '經濟', '金融', '情勢', '1', '經濟',...</td>\n",
              "      <td>壹、國內外經濟金融情勢1經濟研究處說明：一、 國際經濟金融情勢隨全球製造業及貿易活動漸趨活絡...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['多數', '經濟體', '展望', '趨於', '樂觀']</td>\n",
              "      <td>多數經濟體展望趨於樂觀</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['其中', '美國', '、', '日本', '、', '歐元區', '等', '經濟',...</td>\n",
              "      <td>其中美國、日本、歐元區等經濟皆穩健成長亞洲經濟體成長率多高於上年惟中國大陸成長則略緩</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['先進', '經濟體', '因', '經濟', '復甦', '預期', '本年', '通膨...</td>\n",
              "      <td>先進經濟體因經濟復甦預期本年通膨溫和成長</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             sentent  ... labels\n",
              "0  ['討論', '事項', '：', '國內外', '經濟', '金融', '情勢', '與'...  ...      2\n",
              "1  ['壹', '、', '國內外', '經濟', '金融', '情勢', '1', '經濟',...  ...      0\n",
              "2                    ['多數', '經濟體', '展望', '趨於', '樂觀']  ...      0\n",
              "3  ['其中', '美國', '、', '日本', '、', '歐元區', '等', '經濟',...  ...      2\n",
              "4  ['先進', '經濟體', '因', '經濟', '復甦', '預期', '本年', '通膨...  ...      2\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArAU29P727_C",
        "colab_type": "code",
        "outputId": "e178f7ba-1b98-40c4-fe86-0cabc5f27ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "train2 = pd.DataFrame()\n",
        "train2['sentent'] = documents1 + documents2\n",
        "train2['labels'] = trains['labels'].map(lambda x : int(x)).values\n",
        "train2['labels'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    2696\n",
              "1    1023\n",
              "0     531\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBBSnSqhV5au",
        "colab_type": "code",
        "outputId": "84382e67-671c-4bfd-9ca1-df316c63f4d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "train_neu = pd.read_csv('train_neu.csv', encoding = 'big5', header = None)\n",
        "train_neu.fillna(6)\n",
        "trains_neu = pd.DataFrame()\n",
        "trains_neu['sentent'] = train_neu[train_neu[0] == 2.0][1]\n",
        "trains_neu['labels'] = train_neu[train_neu[0] == 2.0][0].map(lambda x : int(x))\n",
        "trains_neu.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentent</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>討論事項：國內外經濟金融情勢與本行貨幣政策提請討論</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>貿易保護主義抬頭可能影響全球貿易復甦</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>國內外主要機構普遍預測本年經濟成長率介於 2.04%至 2.20%</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>如同多數國家實質利率呈現負值</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>銀行授信方面5 月放款與投資成長趨緩年增 5.06%主要係因應所得稅款解繳銀行減持投資部位所致</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentent  labels\n",
              "0                         討論事項：國內外經濟金融情勢與本行貨幣政策提請討論       2\n",
              "4                                貿易保護主義抬頭可能影響全球貿易復甦       2\n",
              "6                 國內外主要機構普遍預測本年經濟成長率介於 2.04%至 2.20%       2\n",
              "11                                   如同多數國家實質利率呈現負值       2\n",
              "14  銀行授信方面5 月放款與投資成長趨緩年增 5.06%主要係因應所得稅款解繳銀行減持投資部位所致       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAkx9cbWz2T5",
        "colab_type": "code",
        "outputId": "70f906cf-3f3b-4bbd-ebb8-d2f8b3af2835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "train_set = train2[train2['labels'] != 2]\n",
        "val_set = train_set.iloc[-250:]\n",
        "train_set = train_set.iloc[:-250]\n",
        "train_set = pd.concat([train_set, trains_neu.iloc[:100]])\n",
        "val_set = pd.concat([val_set, trains_neu.iloc[100:]])\n",
        "index_neu = trains_neu['sentent'].values\n",
        "test_set = train2[train2['labels'] == 2]\n",
        "\n",
        "print(train_set.shape)\n",
        "print(val_set.shape)\n",
        "print(test_set.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1404, 2)\n",
            "(327, 2)\n",
            "(2696, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmVdWTzJsT-H",
        "colab_type": "code",
        "outputId": "bf3c6d60-25e6-49ef-cb4f-1b53fe20d67f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "PRETRAINED_MODEL_NAME = 'bert-base-chinese'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "\n",
        "clear_output()\n",
        "print(f'PyTorch版本 : {torch.__version__}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch版本 : 1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS0xF9qTslf0",
        "colab_type": "code",
        "outputId": "169d5921-131d-49ba-fe5d-7b043fe333a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab = tokenizer.vocab\n",
        "print(f'字典大小 : {len(vocab)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "字典大小 : 21128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltheIeJfsnYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SentimentForCB(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "     \n",
        "        \n",
        "    def __getitem__ (self, idx):\n",
        "        cont = '[CLS]' + self.data['sentent'].iloc[idx]\n",
        "        label = self.data['labels'].iloc[idx]\n",
        "        cont = self.tokenizer.tokenize(cont)\n",
        "        cont = self.tokenizer.convert_tokens_to_ids(cont)\n",
        "        cont = torch.tensor(cont)\n",
        "        label = torch.tensor(label)\n",
        "        \n",
        "        return (cont, label)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPCqXPFBm-Nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def create_minibatch(samples):\n",
        "    \n",
        "    tokens = [s[0] for s in samples]\n",
        "    tokens = pad_sequence(tokens, batch_first=True)\n",
        "    \n",
        "    labels = torch.stack([l[1] for l in samples])\n",
        "    masked = torch.zeros(tokens.shape)\n",
        "    masked = masked.masked_fill(tokens != 0, 1)\n",
        "    \n",
        "    return tokens, masked, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQf_ypXUnIxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_prediction(model, dataloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    prediction = None\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "    with torch.no_grad():\n",
        "        for tok, mas, lb in dataloader:\n",
        "            if use_gpu:\n",
        "                tok = tok.cuda()\n",
        "                mas = mas.cuda()\n",
        "                lb = lb.cuda()                \n",
        "            outputs = model(input_ids = tok, attention_mask = mas)\n",
        "            logits = outputs[0]\n",
        "            _, pred = torch.max(logits.data, 1)\n",
        "        \n",
        "            correct += (pred == lb).sum().item()\n",
        "            total += lb.shape[0]\n",
        "        \n",
        "            if prediction is None:\n",
        "                prediction = pred\n",
        "            else:\n",
        "                prediction = torch.cat((prediction, pred))\n",
        "        acc = correct/total\n",
        "    \n",
        "    return (prediction, acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAIZEeksnAJU",
        "colab_type": "code",
        "outputId": "95c8ee03-6662-43ef-c84a-722860853492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME, num_labels = 3)\n",
        "clear_output()\n",
        "\n",
        "train_dataset = SentimentForCB(train_set, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True, collate_fn = create_minibatch)\n",
        "val_dataset = SentimentForCB(val_set, tokenizer)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = False, collate_fn=  create_minibatch)\n",
        "\n",
        "if use_gpu:\n",
        "    model.cuda()\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (tok, mas, lb) in enumerate(train_loader):\n",
        "        if use_gpu:\n",
        "            tok = tok.cuda()\n",
        "            mas = mas.cuda()\n",
        "            lb = lb.cuda()\n",
        "        batch_size = tok.shape[0]    \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids = tok, attention_mask = mas)\n",
        "        #logits = outputs[0]\n",
        "        _, pred = torch.max(outputs[0], 1)\n",
        "        loss = loss_fn(outputs[0],lb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        correct += (pred == lb).sum().item()\n",
        "        total += lb.shape[0]\n",
        "        train_loss.append(loss.item())\n",
        "    acc = correct/total \n",
        "    \n",
        "    print(f'train [epoch{epoch+1:2d}], acc = {acc:.3f}, loss = {np.mean(train_loss)}')\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = []\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for i, (tok, mas, lb) in enumerate(val_loader):\n",
        "            if use_gpu:\n",
        "                tok = tok.cuda()\n",
        "                mas = mas.cuda()\n",
        "                lb = lb.cuda()   \n",
        "            batch_size = tok.shape[0]        \n",
        "            outputs = model(input_ids = tok, attention_mask = mas)\n",
        "           # logits = outputs[0]     \n",
        "            _, pred = torch.max(outputs[0], 1)\n",
        "            loss = loss_fn(outputs[0],lb)\n",
        "            train_loss.append(loss.item())\n",
        "            correct += (pred == lb).sum().item()\n",
        "            total += lb.shape[0]\n",
        "        acc = correct/total    \n",
        "        print(f'valid [epoch{epoch+1:2d}], acc = {acc:.3f}, loss = {np.mean(train_loss)}')   \n",
        "    if acc > 0.9:\n",
        "      model_path = f'model_{epoch+1}.pkl'\n",
        "      torch.save(model.state_dict(), model_path)\n",
        "      print(f'model_{epoch+1} saved')\n",
        "    print(f'spend {time.time()-start:3.1f}s')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train [epoch 1], acc = 0.667, loss = 0.730697882107713\n",
            "valid [epoch 1], acc = 0.667, loss = 0.5795794931196031\n",
            "spend 33.7s\n",
            "train [epoch 2], acc = 0.865, loss = 0.36322202398018405\n",
            "valid [epoch 2], acc = 0.865, loss = 0.36671888047740575\n",
            "spend 68.1s\n",
            "train [epoch 3], acc = 0.952, loss = 0.1713488853367215\n",
            "valid [epoch 3], acc = 0.869, loss = 0.4142872921767689\n",
            "spend 101.7s\n",
            "train [epoch 4], acc = 0.972, loss = 0.09305391426790845\n",
            "valid [epoch 4], acc = 0.930, loss = 0.28428964884508223\n",
            "model_4 saved\n",
            "spend 137.0s\n",
            "train [epoch 5], acc = 0.984, loss = 0.06157800618728453\n",
            "valid [epoch 5], acc = 0.920, loss = 0.32098570253167835\n",
            "model_5 saved\n",
            "spend 172.0s\n",
            "train [epoch 6], acc = 0.993, loss = 0.0285747169083069\n",
            "valid [epoch 6], acc = 0.887, loss = 0.4756282912123771\n",
            "spend 205.9s\n",
            "train [epoch 7], acc = 0.995, loss = 0.02446222641050223\n",
            "valid [epoch 7], acc = 0.920, loss = 0.3598236647390184\n",
            "model_7 saved\n",
            "spend 241.2s\n",
            "train [epoch 8], acc = 0.995, loss = 0.015285781330683014\n",
            "valid [epoch 8], acc = 0.881, loss = 0.552115563480627\n",
            "spend 275.2s\n",
            "train [epoch 9], acc = 0.996, loss = 0.01798623365572315\n",
            "valid [epoch 9], acc = 0.914, loss = 0.3857463523745537\n",
            "model_9 saved\n",
            "spend 310.2s\n",
            "train [epoch10], acc = 0.994, loss = 0.017459574351298877\n",
            "valid [epoch10], acc = 0.884, loss = 0.4867551497050694\n",
            "spend 344.3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZL0iJGGnoLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_dataset = SentimentForCB(test_set, tokenizer)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 16, collate_fn=create_minibatch)\n",
        "\n",
        "model.load_state_dict(torch.load('model_4.pkl'))\n",
        "model.cuda()\n",
        "with torch.no_grad():\n",
        "    predict_value = []\n",
        "    for tok, mas, lb in test_loader:\n",
        "        if use_gpu:\n",
        "            tok = tok.cuda()\n",
        "            mas = mas.cuda()\n",
        "            lb = lb.cuda()\n",
        "        outputs = model(input_ids = tok, attention_mask = mas)\n",
        "        \n",
        "        _, pred = torch.max(outputs[0], 1)\n",
        "        predict_value += pred.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGVIs2dXY5Wt",
        "colab_type": "code",
        "outputId": "d52abdd6-2ead-43a7-805f-b0a451fb8d52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predict_value[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 1, 1, 1, 0, 2, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqbvEe34jWKN",
        "colab_type": "code",
        "outputId": "24adc3fa-30d8-41ba-d1da-75e6cc2c2fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "test_set['labels'] = predict_value\n",
        "test_set.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentent</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>討論事項：國內外經濟金融情勢與本行貨幣政策，提請討論</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>其中，美國、日本、歐元區等經濟皆穩健成長，亞洲經濟體成長率多高於上年，惟中國大陸成長則略緩</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>先進經濟體因經濟復甦，預期本年通膨溫和成長</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>新興市場經濟體則因部分國家幣值回升及政策調控，高通膨現象可望緩解</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>惟全球政策不確定性(EPU 指數)上升，且 Fed 期望自本年下半年開始縮減資產負債表規模，...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             sentent  labels\n",
              "0                         討論事項：國內外經濟金融情勢與本行貨幣政策，提請討論       1\n",
              "3      其中，美國、日本、歐元區等經濟皆穩健成長，亞洲經濟體成長率多高於上年，惟中國大陸成長則略緩       0\n",
              "4                              先進經濟體因經濟復甦，預期本年通膨溫和成長       0\n",
              "5                   新興市場經濟體則因部分國家幣值回升及政策調控，高通膨現象可望緩解       0\n",
              "7  惟全球政策不確定性(EPU 指數)上升，且 Fed 期望自本年下半年開始縮減資產負債表規模，...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHJCp9VPjde_",
        "colab_type": "code",
        "outputId": "f78ef4da-c9c2-45ae-ca46-2b6c7dbc0459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "test_set['labels'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1326\n",
              "1    1109\n",
              "2     261\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYu4SgT-z7Be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set.to_csv('test_set.csv', index = None)\n",
        "files.download('test_set.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRLrvVSp0a7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}